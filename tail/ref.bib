@misc{abdulkadirAustauschZurBachelorarbeit2025,
  title = {Austausch zur Bachelorarbeit},
  namea = {Abdulkadir, Ahmed},
  nameatype = {collaborator},
  date = {2025-09-04},
  url = {https://teams.microsoft.com/l/meetup-join/19%3ameeting_NTRjZmVkOTgtN2FlMC00MzMxLThlZGItZWFmYzgzNzFlNDIy%40thread.v2/0?context=%7b%22Tid%22%3a%225d1a9f9d-201f-4a10-b983-451cf65cbc1e%22%2c%22Oid%22%3a%22f9007b72-54cb-4536-a294-933ef964b39f%22%7d},
  langid = {ngerman}
}

@book{aggarwalNeuralNetworksDeep2023,
  title = {Neural {{Networks}} and {{Deep Learning}}: {{A Textbook}}},
  shorttitle = {Neural {{Networks}} and {{Deep Learning}}},
  author = {Aggarwal, Charu C.},
  date = {2023},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-29642-0},
  url = {https://link.springer.com/10.1007/978-3-031-29642-0},
  urldate = {2025-04-07},
  isbn = {978-3-031-29641-3 978-3-031-29642-0},
  langid = {english},
  file = {/Users/zhaw/Zotero/storage/7QDX4IBM/Aggarwal - 2023 - Neural Networks and Deep Learning A Textbook.pdf}
}

@misc{AmtlichesGemeindeverzeichnisSchweiz,
  title = {Amtliches Gemeindeverzeichnis der Schweiz - MS-Excel Version},
  url = {https://dam-api.bfs.admin.ch/hub/api/dam/assets/286080/master},
  urldate = {2025-02-25},
  langid = {DE/FR},
  organization = {BFS},
  annotation = {Backup Publisher: Bundesamt für Statistik (BFS)},
  file = {/Users/zhaw/Zotero/storage/LGC52SZ2/be-b-00.04-agv-20050313.xls}
}

@article{chawlaSMOTESyntheticMinority2002,
  title = {{{SMOTE}}: {{Synthetic Minority Over-sampling Technique}}},
  shorttitle = {{{SMOTE}}},
  author = {Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
  date = {2002-06-01},
  journaltitle = {Journal of Artificial Intelligence Research},
  shortjournal = {jair},
  volume = {16},
  pages = {321--357},
  issn = {1076-9757},
  doi = {10.1613/jair.953},
  url = {https://www.jair.org/index.php/jair/article/view/10302},
  urldate = {2025-04-07},
  abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of “normal” examples with only a small percentage of “abnormal” or “interesting” examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
  langid = {english},
  file = {/Users/zhaw/Zotero/storage/HFRT5P7E/Chawla et al. - 2002 - SMOTE Synthetic Minority Over-sampling Technique.pdf}
}

@online{designerpartSchuettgutGewichtBigBag,
  title = {Schüttgut-Gewicht - Big Bag Puhm | Alles über Gewicht und Volumen},
  author = {Designerpart},
  url = {https://bigbag-puhm.at/handhabung/schuettgut-gewicht/},
  urldate = {2025-05-06},
  abstract = {Wie viel Gewicht kann ein Big Bag tragen? Erfahren Sie alles über das Schüttgut-Gewicht und wie Sie es optimal nutzen können.},
  langid = {ngerman},
  organization = {BigBag Puhm},
  file = {/Users/zhaw/Zotero/storage/93ZXILMS/schuettgut-gewicht.html}
}

@dataset{dmg_xl,
  type = {excel},
  title = {USDB\_1972\_2023\_ohneSchadenszahlen\_ohneBeschriebe},
  author = {Swiss Federal Research Institute WSL},
  date = {2023},
  number = {Schadenszahlen},
  langid = {ngerman},
  file = {/Users/zhaw/Zotero/storage/EVC9HQR4/USDB_1972_2023_ohneSchadenszahlen_ohneBeschriebe.xlsx}
}

@misc{duchaudPhoneCallHochbau2025,
  title = {Phone call Hochbau und Umwelt Affoltern am Albis},
  namea = {{Duchaud"}},
  nameatype = {collaborator},
  date = {2025-08-04},
  langid = {ngerman}
}

@article{eilanderGloballyApplicableFramework2023,
  title = {A Globally Applicable Framework for Compound Flood Hazard Modeling},
  author = {Eilander, Dirk and Couasnon, Anaïs and Leijnse, Tim and Ikeuchi, Hiroaki and Yamazaki, Dai and Muis, Sanne and Dullaart, Job and Haag, Arjen and Winsemius, Hessel C. and Ward, Philip J.},
  date = {2023-02-27},
  journaltitle = {Natural Hazards and Earth System Sciences},
  volume = {23},
  number = {2},
  pages = {823--846},
  publisher = {Copernicus GmbH},
  issn = {1561-8633},
  doi = {10.5194/nhess-23-823-2023},
  url = {https://nhess.copernicus.org/articles/23/823/2023/},
  urldate = {2025-04-21},
  abstract = {Coastal river deltas are susceptible to flooding from pluvial, fluvial, and coastal flood drivers. Compound floods, which result from the co-occurrence of two or more of these drivers, typically exacerbate impacts compared to floods from a single driver. While several global flood models have been developed, these do not account for compound flooding. Local-scale compound flood models provide state-of-the-art analyses but are hard to scale to other regions as these typically are based on local datasets. Hence, there is a need for globally applicable compound flood hazard modeling. We develop, validate, and apply a framework for compound flood hazard modeling that accounts for interactions between all drivers. It consists of the high-resolution 2D hydrodynamic Super-Fast INundation of CoastS (SFINCS) model, which is automatically set up from global datasets and coupled with a global hydrodynamic river routing model and a global surge and tide model. To test the framework, we simulate two historical compound flood events, Tropical Cyclone Idai and Tropical Cyclone Eloise in the Sofala province of Mozambique, and compare the simulated flood extents to satellite-derived extents on multiple days for both events. Compared to the global CaMa-Flood model, the globally applicable model generally performs better in terms of the critical success index (−0.01–0.09) and hit rate (0.11–0.22) but worse in terms of the false-alarm ratio (0.04–0.14). Furthermore, the simulated flood depth maps are more realistic due to better floodplain connectivity and provide a more comprehensive picture as direct coastal flooding and pluvial flooding are simulated. Using the new framework, we determine the dominant flood drivers and transition zones between flood drivers. These vary significantly between both events because of differences in the magnitude of and time lag between the flood drivers. We argue that a wide range of plausible events should be investigated to obtain a robust understanding of compound flood interactions, which is important to understand for flood adaptation, preparedness, and response. As the model setup and coupling is automated, reproducible, and globally applicable, the presented framework is a promising step forward towards large-scale compound flood hazard modeling.},
  langid = {english},
  file = {/Users/zhaw/Zotero/storage/8DUL3E5A/Eilander et al. - 2023 - A globally applicable framework for compound flood hazard modeling.pdf}
}

@inreference{Erdrutsch2025,
  title = {Erdrutsch},
  booktitle = {Wikipedia},
  date = {2025-01-13T08:40:48Z},
  url = {https://de.wikipedia.org/w/index.php?title=Erdrutsch&oldid=252204629},
  urldate = {2025-05-04},
  abstract = {Ein Erdrutsch ist das Abgleiten größerer Erd- und Gesteinsmassen, meistens ausgelöst durch starke Niederschläge (langandauernder Regen oder Starkregen) und das dadurch bedingte Eindringen von Wasser zwischen vorher gebundene Bodenschichten. Durch die Schwerkraft und die Verminderung der Haftreibung zwischen den Bodenschichten rutscht der Hang (bei ausreichend großer Hangneigung) ab. Ein großer Erdrutsch wird auch Bergrutsch genannt; wenn kleine Flächen betroffen sind, auch Hangrutsch oder Hangrutschung. Ein Erdrutsch unterscheidet sich vom Bergsturz durch die geringere Geschwindigkeit.},
  langid = {ngerman},
  annotation = {Page Version ID: 252204629},
  file = {/Users/zhaw/Zotero/storage/PLVCIDVH/Erdrutsch.html}
}

@letter{fachstellegisAREJIRAGIS2262EXTERN,
  type = {E-mail},
  title = {[{{ARE-JIRA}}] {{GIS-2262}} [{{EXTERN}}] {{Bodenbeschaffenheitskarte}}},
  author = {Fachstelle GIS},
  file = {/Users/zhaw/Zotero/storage/U6UCPCA9/Fachstelle GIS - [ARE-JIRA] GIS-2262 [EXTERN] Bodenbeschaffenheitskarte.pdf}
}

@online{GeocodingAPIAPI,
  title = {Geocoding {{API}} - {{API Ninjas}}},
  url = {https://www.api-ninjas.com/api/geocoding},
  urldate = {2025-03-08},
  file = {/Users/zhaw/Zotero/storage/LT94STBZ/geocoding.html}
}

@online{GeoHack00,
  title = {{{GeoHack}} (0; 0)},
  url = {https://geohack.toolforge.org/geohack.php?params=___N____E},
  urldate = {2025-03-07},
  file = {/Users/zhaw/Zotero/storage/CBXUHRIX/geohack.html}
}

@online{GISBrowserGeoportalKanton,
  title = {{{GIS-Browser Geoportal Kanton Zürich}}},
  url = {https://geo.zh.ch/maps?x=2693065&y=1253028&scale=279770&basemap=arelkbackgroundzh},
  urldate = {2025-05-06},
  file = {/Users/zhaw/Zotero/storage/454W8TPD/maps.html}
}

@inproceedings{guptaHebbNetSimplifiedHebbian2021,
  title = {{{HebbNet}}: {{A Simplified Hebbian Learning Framework}} to Do {{Biologically Plausible Learning}}},
  shorttitle = {{{HebbNet}}},
  booktitle = {{{ICASSP}} 2021 - 2021 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Gupta, Manas and Ambikapathi, ArulMurugan and Ramasamy, Savitha},
  date = {2021-06-06},
  pages = {3115--3119},
  publisher = {IEEE},
  location = {Toronto, ON, Canada},
  doi = {10.1109/ICASSP39728.2021.9414241},
  url = {https://ieeexplore.ieee.org/document/9414241/},
  urldate = {2024-12-17},
  abstract = {Backpropagation has revolutionized neural network training however, its biological plausibility remains questionable. Hebbian learning, a completely unsupervised and feedback free learning technique is a strong contender for a biologically plausible alternative. However, so far, it has neither achieved high accuracy performance vs. backprop, nor is the training procedure simple. In this work, we introduce a new Hebbian learning based neural network, called HebbNet. At the heart of HebbNet is an improved Hebbian approach that includes an updated activation threshold and gradient sparsity to the first principles of Hebbian learning. These enable an efficiently performing Hebbian approach with a simple training procedure. Further to this, the improved Hebbian rule also improves training dynamics by reducing the number of training epochs from 1500 to 200 and making training a one-step process from a two-step process. We also reduce heuristics by reducing hyper-parameters from 5 to 1, and number of search runs for hyper-parameter tuning from 12,600 to 13. Notwithstanding this, HebbNet still achieves strong test performance on MNIST and CIFAR-10 datasets vs. state-of-the-art.},
  eventtitle = {{{ICASSP}} 2021 - 2021 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-7281-7605-5},
  langid = {english},
  file = {/Users/zhaw/Zotero/storage/C63KLYG8/Gupta et al. - 2021 - HebbNet A Simplified Hebbian Learning Framework to do Biologically Plausible Learning.pdf}
}

@misc{hersbachERA5HourlyData2023,
  title = {{{ERA5}} Hourly Data on Single Levels from 1940 to Present},
  author = {Hersbach, H., Bell, B., Berrisford, P., Biavati, G., Horányi, A., Muñoz Sabater, J., Nicolas, J., Peubey, C., Radu, R., Rozum, I., Schepers, D., Simmons, A., Soci, C., Dee, D., Thépaut, J-N.},
  date = {2023},
  doi = {10.24381/cds.adbb2d47},
  url = {https://cds.climate.copernicus.eu/doi/10.24381/cds.adbb2d47},
  organization = {ECMWF}
}

@article{kaurSystematicReviewImbalanced2020,
  title = {A {{Systematic Review}} on {{Imbalanced Data Challenges}} in {{Machine Learning}}: {{Applications}} and {{Solutions}}},
  shorttitle = {A {{Systematic Review}} on {{Imbalanced Data Challenges}} in {{Machine Learning}}},
  author = {Kaur, Harsurinder and Pannu, Husanbir Singh and Malhi, Avleen Kaur},
  date = {2020-07-31},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {52},
  number = {4},
  pages = {1--36},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3343440},
  url = {https://dl.acm.org/doi/10.1145/3343440},
  urldate = {2025-04-03},
  abstract = {In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.},
  langid = {english}
}

@online{kingmaAdamMethodStochastic2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  date = {2017-01-30},
  eprint = {1412.6980},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1412.6980},
  url = {http://arxiv.org/abs/1412.6980},
  urldate = {2025-05-06},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/zhaw/Zotero/storage/MAJJEPUZ/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/Users/zhaw/Zotero/storage/43U4254A/1412.html}
}

@misc{liechtiAustauschUnwetterschaedenUnd2025,
  title = {Austausch zu Unwetterschäden und Daten},
  namea = {Liechti, Katharina},
  nameatype = {collaborator},
  date = {2025-02-28},
  url = {https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZDk5ODM1MWQtN2E2Yi00NDZjLWFiNTEtOWE0ZWU4ODQ3YzA1%40thread.v2/0?context=%7b%22Tid%22%3a%225d1a9f9d-201f-4a10-b983-451cf65cbc1e%22%2c%22Oid%22%3a%225f85a69b-df7a-4a9a-acab-f5ad7d25b1a9%22%7d},
  langid = {ngerman}
}

@letter{liechtiREAnfrageZur2024,
  type = {E-mail},
  title = {{{RE}}: {{Anfrage}} Zur {{Nutzung}} Der {{Unwetterschadens-Datenbank}} Für {{Bachelorarbeit}}},
  author = {Liechti, Käthi},
  date = {2024-11-29}
}

@online{limTemporalFusionTransformers2020,
  title = {Temporal {{Fusion Transformers}} for {{Interpretable Multi-horizon Time Series Forecasting}}},
  author = {Lim, Bryan and Arik, Sercan O. and Loeff, Nicolas and Pfister, Tomas},
  date = {2020-09-27},
  eprint = {1912.09363},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.1912.09363},
  url = {http://arxiv.org/abs/1912.09363},
  urldate = {2025-04-29},
  abstract = {Multi-horizon forecasting problems often contain a complex mix of inputs -- including static (i.e. time-invariant) covariates, known future inputs, and other exogenous time series that are only observed historically -- without any prior information on how they interact with the target. While several deep learning models have been proposed for multi-step prediction, they typically comprise black-box models which do not account for the full range of inputs present in common scenarios. In this paper, we introduce the Temporal Fusion Transformer (TFT) -- a novel attention-based architecture which combines high-performance multi-horizon forecasting with interpretable insights into temporal dynamics. To learn temporal relationships at different scales, the TFT utilizes recurrent layers for local processing and interpretable self-attention layers for learning long-term dependencies. The TFT also uses specialized components for the judicious selection of relevant features and a series of gating layers to suppress unnecessary components, enabling high performance in a wide range of regimes. On a variety of real-world datasets, we demonstrate significant performance improvements over existing benchmarks, and showcase three practical interpretability use-cases of TFT.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/zhaw/Zotero/storage/PNGFABV8/Lim et al. - 2020 - Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting.pdf;/Users/zhaw/Zotero/storage/5ZJ6W6QG/1912.html}
}

@online{LoginOpenStackDashboard,
  title = {Login - {{OpenStack Dashboard}}},
  url = {https://apu.cloudlab.zhaw.ch/auth/login/?next=/},
  urldate = {2025-05-06},
  file = {/Users/zhaw/Zotero/storage/932T52Y3/login.html}
}

@online{MapsSwitzerlandSwiss,
  title = {Maps of {{Switzerland}} - {{Swiss Confederation}} - Map.Geo.Admin.Ch},
  url = {https://map.geo.admin.ch/#/map?lang=en&center=2660000,1190000&z=1&topic=ech&layers=ch.swisstopo.zeitreihen@year=1864,f;ch.bfs.gebaeude_wohnungs_register,f;ch.bav.haltestellen-oev,f;ch.swisstopo.swisstlm3d-wanderwege,f;ch.vbs.schiessanzeigen,f;ch.astra.wanderland-sperrungen_umleitungen,f&bgLayer=ch.swisstopo.pixelkarte-farbe},
  urldate = {2025-05-06},
  file = {/Users/zhaw/Zotero/storage/PSNEH2XI/map.geo.admin.ch.html}
}

@online{mariaGewichtNasserErde2020,
  title = {Gewicht nasser Erde: Formel zum Umrechnen},
  shorttitle = {Gewicht nasser Erde},
  author = {Maria},
  date = {2020-08-04T13:39:00+00:00},
  url = {https://hortica.de/gewicht-nasse-erde/},
  urldate = {2025-05-06},
  abstract = {Spätestens wenn Sie Ihren Garten neu gestalten und eine große Menge Erde transportieren wollen, müssen Sie wissen, wie viel nasse Erde wiegt.},
  langid = {ngerman},
  organization = {Hortica},
  file = {/Users/zhaw/Zotero/storage/624MP5H5/gewicht-nasse-erde.html}
}

@online{MeteoSwissIDAWEBLogin,
  title = {{{MeteoSwiss IDAWEB}}: {{Login}} at {{IDAWEB}}},
  url = {https://gate.meteoswiss.ch/idaweb/login.do},
  urldate = {2025-05-06},
  file = {/Users/zhaw/Zotero/storage/D93XBZ9S/login.html}
}

@unpublished{mrazovaMultilayeredNeuralNetworks,
  title = {Multi-Layered {{Neural Networks}}},
  author = {Mrázová, Iveta},
  eventtitle = {Neural {{Networks NAIL069}}},
  langid = {english},
  venue = {Charles University, Prague},
  file = {/Users/zhaw/Zotero/storage/HZN4VPKU/NN-lecture_24-Multi-Layered_NN_F.pdf}
}

@misc{muellerPhoneCallAmt2025,
  title = {phone call Amt für Raum Entwicklung und Vermessung},
  namea = {Müller},
  nameatype = {collaborator},
  date = {2025-08-04},
  langid = {ngerman}
}

@online{NNSVG,
  title = {{{NN SVG}}},
  url = {http://alexlenail.me/NN-SVG/},
  urldate = {2025-05-03},
  file = {/Users/zhaw/Zotero/storage/4C882D58/NN-SVG.html}
}

@misc{PhoneCallHochbau2025,
  title = {phone call Hochbau Amt Zürich},
  date = {2025-08-04},
  langid = {ngerman}
}

@online{PyTorchFoundation,
  title = {{{PyTorch Foundation}}},
  url = {https://pytorch.org/},
  urldate = {2025-05-06},
  abstract = {PyTorch Foundation is the deep learning community home for the open source PyTorch framework and ecosystem.},
  langid = {american},
  organization = {PyTorch},
  file = {/Users/zhaw/Zotero/storage/I4G9IY43/pytorch.org.html}
}

@online{RecipeTrainingNeural,
  title = {A {{Recipe}} for {{Training Neural Networks}}},
  url = {http://karpathy.github.io/2019/04/25/recipe/},
  urldate = {2025-03-12},
  file = {/Users/zhaw/Zotero/storage/CTCP6DZH/recipe.html}
}

@online{RecipeTrainingNeurala,
  title = {A {{Recipe}} for {{Training Neural Networks}}},
  url = {http://karpathy.github.io/2019/04/25/recipe/},
  urldate = {2025-03-12},
  file = {/Users/zhaw/Zotero/storage/6UACH873/recipe.html}
}

@unpublished{schillingLecture05Sequential2025,
  title = {Lecture 05: {{Sequential Models}}},
  author = {Schilling, Frank-Peter and Cai, Zhaw},
  date = {2025-03-19},
  langid = {english},
  venue = {ZHAW School of Engineering},
  file = {/Users/zhaw/Zotero/storage/G4M3RAG4/Schilling and Cai - Lecture 05 Sequential Models.pdf}
}

@online{ScikitlearnMachineLearning,
  title = {Scikit-Learn: Machine Learning in {{Python}} — Scikit-Learn 1.6.1 Documentation},
  url = {https://scikit-learn.org/stable/#},
  urldate = {2025-05-06},
  file = {/Users/zhaw/Zotero/storage/MSSC79Z8/stable.html}
}

@article{sherstinskyFundamentalsRecurrentNeural2020,
  title = {Fundamentals of {{Recurrent Neural Network}} ({{RNN}}) and {{Long Short-Term Memory}} ({{LSTM}}) Network},
  author = {Sherstinsky, Alex},
  date = {2020-03},
  journaltitle = {Physica D: Nonlinear Phenomena},
  shortjournal = {Physica D: Nonlinear Phenomena},
  volume = {404},
  pages = {132306},
  issn = {01672789},
  doi = {10.1016/j.physd.2019.132306},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167278919305974},
  urldate = {2025-04-16},
  abstract = {Because of their effectiveness in broad practical applications, LSTM networks have received a wealth of coverage in scientific journals, technical blogs, and implementation guides. However, in most articles, the inference formulas for the LSTM network and its parent, RNN, are stated axiomatically, while the training formulas are omitted altogether. In addition, the technique of ‘‘unrolling’’ an RNN is routinely presented without justification throughout the literature. The goal of this tutorial is to explain the essential RNN and LSTM fundamentals in a single document. Drawing from concepts in Signal Processing, we formally derive the canonical RNN formulation from differential equations. We then propose and prove a precise statement, which yields the RNN unrolling technique. We also review the difficulties with training the standard RNN and address them by transforming the RNN into the ‘‘Vanilla LSTM’’1 network through a series of logical arguments. We provide all equations pertaining to the LSTM system together with detailed descriptions of its constituent entities. Albeit unconventional, our choice of notation and the method for presenting the LSTM system emphasizes ease of understanding. As part of the analysis, we identify new opportunities to enrich the LSTM system and incorporate these extensions into the Vanilla LSTM network, producing the most general LSTM variant to date. The target reader has already been exposed to RNNs and LSTM networks through numerous available resources and is open to an alternative pedagogical approach. A Machine Learning practitioner seeking guidance for implementing our new augmented LSTM model in software for experimentation and research will find the insights and derivations in this treatise valuable as well.},
  langid = {english},
  file = {/Users/zhaw/Zotero/storage/C7HMH6Q9/Sherstinsky - 2020 - Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network.pdf}
}

@online{shrivastavaCrossValidationTime2020,
  title = {Cross {{Validation}} in {{Time Series}}},
  author = {Shrivastava, Soumya},
  date = {2020-01-17T05:52:39},
  url = {https://medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4},
  urldate = {2025-04-24},
  abstract = {Cross Validation:},
  langid = {english},
  organization = {Medium},
  file = {/Users/zhaw/Zotero/storage/PYBN94DW/cross-validation-in-time-series-566ae4981ce4.html}
}

@article{sunDevelopmentLSTMBroadcasting2022,
  title = {Development of an {{LSTM}} Broadcasting Deep-Learning Framework for Regional Air Pollution Forecast Improvement},
  author = {Sun, Haochen and Fung, Jimmy C. H. and Chen, Yiang and Li, Zhenning and Yuan, Dehao and Chen, Wanying and Lu, Xingcheng},
  date = {2022-11-21},
  journaltitle = {Geoscientific Model Development},
  volume = {15},
  number = {22},
  pages = {8439--8452},
  publisher = {Copernicus GmbH},
  issn = {1991-959X},
  doi = {10.5194/gmd-15-8439-2022},
  url = {https://gmd.copernicus.org/articles/15/8439/2022/},
  urldate = {2025-04-29},
  abstract = {Deep-learning frameworks can effectively forecast the air pollution data for individual stations by decoding time series data. However, most of the existing time-series-based deep-learning models use offline spatial interpolation strategies and thus cannot reliably project the station-based forecast to the spatial region of interest. In this study, the station-based long short-term memory (LSTM) technique was extended for spatial air quality forecasting by combining a novel deep-learning layer, termed the broadcasting layer, which incorporates a learnable weight decay parameter designed for point-to-area extension. Unlike most existing deep-learning-based methods that isolate the interpolation from the model training process, the proposed end-to-end LSTM broadcasting framework can consider the temporal characteristics of the time series and spatial relationships among different stations. To validate the proposed deep-learning framework, PM2.5 and O3 forecasts for the next 48 h were obtained using 3D chemical transport model simulation results and ground observation data as the inputs. The root mean square error associated with the proposed framework was 40 \% and 20 \% lower than those of the Weather Research and Forecasting–Community Multiscale Air Quality model and an offline combination of the deep-learning and spatial interpolation methods, respectively. The novel LSTM broadcasting framework can be extended for air pollution forecasting in other regions of interest.},
  langid = {english},
  file = {/Users/zhaw/Zotero/storage/GP8NJSI8/Sun et al. - 2022 - Development of an LSTM broadcasting deep-learning framework for regional air pollution forecast impr.pdf}
}

@online{sutskeverSequenceSequenceLearning2014,
  title = {Sequence to {{Sequence Learning}} with {{Neural Networks}}},
  author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
  date = {2014-12-14},
  eprint = {1409.3215},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1409.3215},
  url = {http://arxiv.org/abs/1409.3215},
  urldate = {2025-04-22},
  abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT’14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM’s BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM’s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/zhaw/Zotero/storage/M7GEUZXP/Sutskever et al. - 2014 - Sequence to Sequence Learning with Neural Networks.pdf}
}

@misc{swissfederalresearchinstitutewslInfos_Daten_Unwetterschadensdatenbank_WSL_english2023,
  title = {Infos\_{{Daten}}\_{{Unwetterschadensdatenbank}}\_{{WSL}}\_english},
  shorttitle = {{{WSL-Disclaimer}}},
  author = {Swiss Federal Research Institute WSL},
  date = {2023},
  url = {Email from K. Liechti},
  urldate = {2024-11-29},
  langid = {english},
  organization = {Swiss Federal Research Institute WSL},
  file = {/Users/zhaw/Zotero/storage/92G9GY62/Infos_Daten_Unwetterschadensdatenbank_WSL_english.pdf}
}

@online{systemadmin_umweltHochwasserWieSie2012,
  type = {Text},
  title = {Hochwasser – wie sie entstehen und wie der Mensch sie beeinflusst},
  author = {Systemadmin\_Umwelt},
  date = {2012-06-13T12:00+02:00},
  publisher = {Umweltbundesamt},
  url = {https://www.umweltbundesamt.de/themen/wasser/extremereignisse/hochwasser},
  urldate = {2025-05-04},
  abstract = {Hochwasser sind natürliche Ereignisse, sie treten regelmäßig auf und sind fester Bestandteil des Abflussgeschehens. Die Entstehung von Hochwasser hängt von der Stärke der Niederschläge, den Eigenschaften des Einzugsgebietes und vom Fluss ab. Der Mensch kann Hochwasser, ihren Verlauf und die Auswirkungen beeinflussen und verstärken.},
  langid = {ngerman},
  organization = {Umweltbundesamt},
  file = {/Users/zhaw/Zotero/storage/9DQUH5J5/hochwasser.html}
}

@online{thakurLSTMItsEquations2018,
  title = {{{LSTM}} and Its Equations},
  author = {Thakur, Divyanshu},
  date = {2018-07-06T09:44:04},
  url = {https://medium.com/@divyanshu132/lstm-and-its-equations-5ee9246d04af},
  urldate = {2025-05-05},
  abstract = {LSTM stands for Long Short Term Memory, I myself found it difficult to directly understand LSTM without any prior knowledge of the Gates…},
  langid = {english},
  organization = {Medium},
  file = {/Users/zhaw/Zotero/storage/D27EBK8B/lstm-and-its-equations-5ee9246d04af.html}
}

@letter{ueltschiBodenbeschaffenheitskarte,
  type = {E-mail},
  title = {Bodenbeschaffenheitskarte},
  author = {Ueltschi, Damian},
  file = {/Users/zhaw/Zotero/storage/CEVUFKLJ/Ueltschi - Bodenbeschaffenheitskarte.pdf}
}

@online{VergrabenUndVergessen2019,
  title = {Vergraben und vergessen},
  date = {2019-04-02},
  url = {https://www.derbund.ch/vergraben-und-vergessen-413137488243},
  urldate = {2025-05-06},
  abstract = {Seit Jahrzehnten sucht der Bund Endlager für radioaktive Abfälle. In Bülach ZH fährt jetzt erstmals ein Bohrer auf – ohne nennenswerten Widerstand.},
  langid = {ngerman},
  organization = {Der Bund},
  file = {/Users/zhaw/Zotero/storage/5B3VX5W8/vergraben-und-vergessen-413137488243.html}
}

@online{WieEntstehtHochwasser,
  title = {Wie Entsteht {{Hochwasser}}? | {{Nds}}. {{Landesbetrieb}} Für {{Wasserwirtschaft}}, {{Küsten-}} Und {{Naturschutz}}},
  url = {https://www.nlwkn.niedersachsen.de/hochwasserschutz/hintergrundinformationen/wie_entsteht_hochwasser/fachliche-grundlagen-wie-entsteht-hochwasser-119741.html},
  urldate = {2025-05-04},
  file = {/Users/zhaw/Zotero/storage/TMNHR3RI/fachliche-grundlagen-wie-entsteht-hochwasser-119741.html}
}

@online{yadavPyTorchEmbeddingLayer2025,
  title = {{{PyTorch Embedding Layer}} for {{Categorical Data}}},
  author = {Yadav, Amit},
  date = {2025-04-18T00:31:11},
  url = {https://medium.com/biased-algorithms/pytorch-embedding-layer-for-categorical-data-096af5757353},
  urldate = {2025-04-29},
  abstract = {“If you can’t explain it simply, you don’t understand it well enough.”{$\mkern1mu$}—{$\mkern1mu$}Albert Einstein.},
  langid = {english},
  organization = {Biased-Algorithms},
  file = {/Users/zhaw/Zotero/storage/W7H8DYDI/pytorch-embedding-layer-for-categorical-data-096af5757353.html}
}

@article{yuSpatialTemporalCombination2024,
  title = {Spatial–Temporal Combination and Multi-Head Flow-Attention Network for Traffic Flow Prediction},
  author = {Yu, Lianfei and Liu, Wenbo and Wu, Dong and Xie, Dongmei and Cai, Chuang and Qu, Zhijian and Li, Panjing},
  date = {2024-04-26},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {14},
  number = {1},
  pages = {9604},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-024-60337-7},
  url = {https://www.nature.com/articles/s41598-024-60337-7},
  urldate = {2025-04-29},
  abstract = {Traffic flow prediction based on spatial–temporal data plays a vital role in traffic management. However, it still faces serious challenges due to the complex spatial–temporal correlation in nonlinear spatial–temporal data. Some previous methods have limited ability to capture spatial–temporal correlation, and ignore the quadratic complexity problem in the traditional attention mechanism. To this end, we propose a novel spatial–temporal combination and multi-head flow-attention network (STCMFA) to model the spatial–temporal correlation in road networks. Firstly, we design a temporal sequence multi-head flow attention (TS-MFA), in which the unique source competition mechanism and sink allocation mechanism make the model avoid attention degradation without being affected by inductive biases. Secondly, we use GRU instead of the linear layer in traditional attention to map the input sequence, which further enhances the temporal modeling ability of the model. Finally, we combine the GCN with the TS-MFA module to capture the spatial–temporal correlation, and introduce residual mechanism and feature aggregation strategy to further improve the performance of STCMFA. Extensive experiments on four real-world traffic datasets show that our model has excellent performance and is always significantly better than other baselines.},
  langid = {english},
  keywords = {Computer science,Information technology},
  file = {/Users/zhaw/Zotero/storage/JBSRN592/Yu et al. - 2024 - Spatial–temporal combination and multi-head flow-attention network for traffic flow prediction.pdf}
}

@software{zippenfenigOpenMeteocomWeatherAPI2023,
  title = {Open-{{Meteo}}.Com {{Weather API}}},
  author = {Zippenfenig, Patrick},
  date = {2023},
  doi = {10.5281/zenodo.7970649},
  url = {https://open-meteo.com/}
}

@letter{zippenfenigProfessionalAPIKey,
  type = {E-mail},
  title = {Professional {{API Key}} for {{Research}} Purposes},
  author = {Zippenfenig, Patrick},
  file = {/Users/zhaw/Zotero/storage/WJBPT96S/Zippenfenig - Professional API Key for Research purposes.pdf}
}

@letter{zotero-item-165,
  type = {E-mail}
}
