#import "@preview/abbr:0.2.3"
== Machine Learning
Machine Learning has gained increasing popularity in recent years, particularly through advancements in #abbr.pla[NN]. These developments have significantly expanded the capabilities of automated data-driven modeling across various domains. In this chapter, we focus primarily on #abbr.pla[NN] architectures, as they form the core modeling approach used in this project.


=== Feedforward Neural Networks<fnn>
#abbr.pla[FNN] are a class of machine learning models inspired by the structure and function of the human brain. In biological systems, neurons are interconnected through synapses, and their strengths change in response to external stimuli—a process that underlies learning. #abbr.pla[FNN] mimic this behavior by using computational units, also called neurons, connected by weighted links. These weights are adjusted during training to improve the model's predictions, analogous to synaptic strength adjustments in the brain.

Each artificial neuron receives inputs, scales them using learned weights, applies a non-linear activation function, and forwards the result to subsequent neurons. Through this architecture, an #abbr.a[FNN] models complex functions by propagating signals from input to output layers. Learning in #abbr.pla[FNN] occurs via exposure to training data consisting of input–output pairs. The network adjusts its weights to reduce the difference between its predictions and the target outputs, thereby minimizing the prediction error.

While the biological analogy is imperfect, it has historically guided the development of neural architectures. More formally, #abbr.pla[FNN] can also be viewed as compositions of simple mathematical units—such as logistic or linear regressors—structured into a computational graph. Their expressive power arises from stacking these units into deeper networks, enabling them to approximate highly non-linear relationships in data. This capacity to learn from examples and generalize to unseen inputs makes #abbr.pla[FNN] a powerful tool in modern machine learning.


*Architecture*

An #abbr.a[FNN] trained with backpropagation, which is discussed in @backprop, can be illustrated as a directed acyclic Graph with inter-connections. It contains a set of neurons distributed in different layers.
- Each neuron has a activation function.
- The first layer, shown on the left side in @nn-img, is called the input layer and has no predacessors in the inter-connection graph. Additionally, is their input value the same as their output value.
- The last layer, shown on the right side in @nn-img, is called the output layer and have no successors in the inter-connection graph. Their value represents the output of the Network
- All other neurons are grouped in the so called hidden layers. In @nn-img this is represented by the layer in the middle. A neural network can have an arbitrary amount of hidden layers. 
- The edges in the inter-connection graph, are so called weights, which represent an arbitrary number in $RR$. These weights are updated during the trianing process.

#figure(image("images/Neural_Network_Illustration.png", width: 50%), 
caption: [Illustration of a Neural Network with 3 layers. Illustrated with @NNSVG])
<nn-img>

*Computation of the Output* 

The calculation of the output of the #abbr.a[FNN] is also called a forward pass. To do so, the value of each neuron needs to be calculated. This is done by summing all the inputs and then put this value into a given activation function. Mathematically, this process can be represented as: $y = f(sum_i^n xi_i)$ wher $f$ represents the activation function of the neuron and $xi_i$ the input or also called the potential of a neuron. To compute a full forward pass, this is done for each neuron from the input layer towards the output layer. When a value is passed throughtouh a weight to a successor neuron, the value is multiplied by the value of the weight. This process can then be summarized to:

#math.equation(block: true, supplement: auto, 
$
    y_1 = f(sum_i^n w_(i j) x_i) "[input to hidden layer]"\
    y_(j+1) = f(sum_i^n w_(i j) y_j)  forall j in {1 dots k-1}"[hidden to hidden layer]"\
    o = f(w_(i j+1) y_j) "[hidden to output layer]"
$ 
)<forwardpass> @aggarwalNeuralNetworksDeep2023
where $j$ denotes the layer, ascending from input layer to output layer, $f$ activation function, $w_(i j)$ weight at index $i$ and layer $j$, $x$ as input at index $i$. The state of the neuron in the output layer $o$ can then by denoted as the output vector.


=== The Backpropagation Training Algorithm<backprop>
*Objective*: To identify a set of weights that guarantees that for every input vector, the output vector generated by the network is identical to (or sufficiently close to) the desired output vector.

Note: The actual or desired output values of the hidden neurons are not explicitly specified by the task.

*For a fixed and finite training set*:
The objective function represents the total error between the desired and actual outputs of all the output neurons for all the training patterns.

*Error Function*

#math.equation(
  block: true,
  $
    E = 1 /2 sum_p^P sum_i^N (y_(i p) - d_(i p))^2 
  $
)<errorfunction> @mrazovaMultilayeredNeuralNetworks


where $P$ is the number of training patterns, $N$ the number of output neurons, $d_(i p)$ is the desired output for pattern $p$, $y_(i p)$ the actual output of the neuron $i$ and output neuron $i$.

*Procedure*
#figure(
  box[
    #set align(left)
    1. Compute the actual output for the presented pattern
    2. Compare the actual output with the desired output
    3. Adjustment of weights and thresholds against the gradient of the error function (@errorfunction) for each layer from the output layer towards the input layer
  ], 
  caption: [Training Procedure of the backpropagation algorithm]
)

*Adjustment Rules*

#math.equation(
  block: true,
  $
    w_(i j)(t + 1) = w_(i j) + Delta_E w_(i j) (t) \
    Delta_E w_(i j) = - (partial E) / (partial w_(i j)) = - (partial E) / (partial y_j) (partial y_j) / (partial xi_j) (partial xi_j) / (partial w_(i j))
  $
)#cite(<mrazovaMultilayeredNeuralNetworks>)

where $Delta_E w_(i j)$ denotes the change of the Error Function with respect to $w_(i j)$, $E$ the Error Function, $y_j$ the output of the output neuron $j$, $xi_j$ the potential of the neuron $j$ and $w_(i j)$ the weight with index $i$ at layer $j$.

=== Recurrent Neural Networks
The feedforward #abbr.pla[FNN] discussed in @fnn are inherently limited to fixed-size, unordered input representations. This makes them unsuitable for sequential data, where both the order and length of the input can vary. To address this limitation, we introduce a class of models specifically designed to process variable-length sequences: #abbr.pla[RNN]

*Architecture*
A #abbr.a[RNN] consits of the following components:
- Input signal: The external data which is fed into the network at a timestep $n$ and represent the current information which the network is processing.
- State signal: Also known as the hidden state, represents the memory of the #abbr.a[RNN] for a given neuron. It contains information about the past inputs in the sequence and is updated at each time step based on the current input and the previous state. The hidden state is updated with the following formula: $h_t = f(h_(t-1), x_t)$. After the update, the hidden state of neuron $i$ serves as input into the neuron $i+1$ 
- Weights: The weights of the #abbr.a[RNN] neurons are shared among all different states. 
- Output: Each neuron has a output, which is denoted as $y_1$ - $y_4$ in @fig:unrolled_rnn. This output can serve as the output for the current state or as input into the next neuron.

 #grid(
  columns: 2, align: center,
  grid.cell([
    #figure(
      image("images/rnn_simple.png", height: 40%),
      caption: [#abbr.a[RNN]],
    )<fig:rnn>
  ]),
  grid.cell([
    #figure(
      image("images/rnn_unrolled.png", height: 40%),
      caption: [4 times unrolled #abbr.a[RNN]],
    )<fig:unrolled_rnn>
  ]),
)
*Vanishing Gradient Problem*

The #abbr.a[VGP] is a challenge encountered during the training of of #abbr.pla[RNN], particullary dealing with deep #abbr.pla[RNN] and long input sequences. It arieses from the way how gradients are updated during the backpropagation algorithm (discussed in @backprop), which updates the network's paramertes / weights by propagating gradients backward through each time step. In backpropagation, gradients are computed via the chain rule, resulting in repeated multiplication of weight matrices and derivatives of activation functions across time steps. When these values are consistently smaller than one, the gradients exponentially decrease as they traverse earlier layers or time steps. Consequently, the gradients become vanishingly small, leading to negligible updates for earlier parameters and impairing the network's ability to learn long-range dependencies. The same principle aries, when the gradients become too large. In this case, the problem is called the exploding gradient problem.




=== Long Short Term Memory Neural Networks
#abbr.pla[LSTM] are a special form of #abbr.pla[RNN] designed to address the problem of Vanishing Gradients while having a more fine-grained control over the previous input data. #abbr.pla[LSTM] are an enhanement of #abbr.pla[RNN], because the recurrence conditaions of how the hidden state $h_t$ is processed. To achieve this aim, we introduce a new hidden state of the same dimesion as $h_t$, which is called the cell state and is denoted as $c_t$. 
The key innovation of the #abbr.a[LSTM]  lies in its ability to control the flow of information using a set of gating mechanisms. These gates regulate how information is added to, removed from, or exposed from the cell state. Each gate is implemented as a sigmoid-activated neural layer and serves a distinct role in the update process.

*Architecture*

At each time step $t$ with a given input vector $x_t$, previous hidden state $h_(t-1)$ and previous cell state $c_(t-1)$, the #abbr.a[LSTM] performs the following computations:

- Input Gate: Decides which new information will be added to the cell state and is calculated as:
  - $i_t = sigma(w_i [h_(t-1), x_t] + b_i)$
- Forget Gate: This gate decides which parts of the previous cell state should be forgotten. The value of the forget gate is calculated as: 
  - $f_t = sigma(w_f [h_(t-1), x_t]) + b_f) $
- Candidate Cell State: Computes possible candidates $tilde(c_t)$ which can be added to the cell state, computed as: 
  - $tilde(c_t) = tanh(w_c [h_(t-1), x_t] + b_c)$
- Cell state update: Given the candidates, the cell state can be updated as:
  - $c_t = f_t dot c_(t-1) + i_t dot tilde(c_t)$
- Output Gate: Determines which part of the cell state influences the hidden state and therefore the output. It is computed with: 
  - $o_t = sigma(w_o [h_(t-1), x_t] + b_o)$
- Hidden state update:  The final hidden state is computed by applying the output gate to the activated cell state. It is computed with: 
  - $h_t = o_t dot tanh(c_t)$
Note: $w_x$ represents a complete weight matrix for each gate, $b_x$ denotes the bias for the corresponding gates, and $sigma$ denotes the sigmoid function.


@sherstinskyFundamentalsRecurrentNeural2020 @aggarwalNeuralNetworksDeep2023 @schillingLecture05Sequential2025 @thakurLSTMItsEquations2018
